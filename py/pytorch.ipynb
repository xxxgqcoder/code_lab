{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1f9849-f76f-48b4-b896-0265fad9bb78",
   "metadata": {},
   "source": [
    "# Get accelerator device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ba6d4-a8bb-4577-a41c-aade4d7c7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.accelerator.current_accelerator(\n",
    ") if torch.accelerator.is_available() else 'cpu'\n",
    "print(f'using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70f9d7-ea88-42eb-a5d4-fdc1281ec2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47434836-03f4-4066-bfd5-c01cfb1a41cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532ffa96-ea8f-4474-a6a0-744506653739",
   "metadata": {},
   "source": [
    "# PyTorch training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeaee43-71f2-4140-9461-549255d2a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "epoch_num = 1\n",
    "train_loader = None  # torch dataset loader\n",
    "\n",
    "model = None\n",
    "learning_rate = 5e-6\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epoch_num):\n",
    "    print(f'running epoch: {epoch}')\n",
    "    for batch, (X, Y, loss_mask) in enumerate(train_loader):\n",
    "        # compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        loss_mask = loss_mask.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.view(-1, pred.size(-1)), Y.view(-1)).view(Y.size())\n",
    "\n",
    "        loss = (loss * loss_mask).sum() / loss_mask.sum()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss.item()\n",
    "        print(\n",
    "            f\"{datetime.datetime.now()}, epoch: {epoch}, step: {batch}, loss: {loss}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0eed69-27d8-4186-9600-d8323748c3c5",
   "metadata": {},
   "source": [
    "# Save and load pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d8404-a6bc-4ee3-8780-65e2b9f8b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "def latest_checkpoint(checkpoint_dir):\n",
    "\n",
    "    checkpoints = sorted(os.listdir(checkpoint_dir))\n",
    "    if len(checkpoints) == 0:\n",
    "        return None\n",
    "    return os.path.join(checkpoint_dir, checkpoints[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ca75f-0710-4a54-b63b-665c6ed3e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "device = 'cuda'\n",
    "optimizer = None\n",
    "checkpoint_dir = None\n",
    "\n",
    "# move to device before load state dict\n",
    "model = model.to(device)\n",
    "\n",
    "# load checkpoints\n",
    "start_epoch = 0\n",
    "checkpoint_path = latest_checkpoint(checkpoint_dir)\n",
    "if checkpoint_path is not None:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    start_epoch = int(checkpoint['epoch']) + 1\n",
    "    loss = checkpoint['loss']\n",
    "    print(\n",
    "        f\"loading checkpoint model from {checkpoint_path}, epoch: {checkpoint['epoch']}, loss: {loss}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# save checkpoints\n",
    "epoch = 0\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"model_{epoch:04d}.pt\")\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    },\n",
    "    checkpoint_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8ab47-a948-474d-b358-7ff272728a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7d0c02d-350a-4e94-afa3-d40d40319f10",
   "metadata": {},
   "source": [
    "# Parse loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c930983-29af-4f89-9de4-57c6288e64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = 'pre_train.log'\n",
    "\n",
    "loss_vals = []\n",
    "with open(log_path) as f:\n",
    "    for line in f:\n",
    "        loss = re.search(r\"loss:\\s*([0-9]+\\.[0-9]+)\", line)\n",
    "        if loss:\n",
    "            loss_val = loss.group(1)\n",
    "            loss_vals.append(float(loss_val))\n",
    "\n",
    "\n",
    "loss_df = pd.DataFrame(loss_vals, columns=['loss'])\n",
    "\n",
    "loss_df['loss'].plot(grid=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
