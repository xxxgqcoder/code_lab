{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6577c2b1",
   "metadata": {},
   "source": [
    "# filtered parsed tfrecord data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c390a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds  = None # tf dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f088726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_target(feat, target, weight, meta):\n",
    "    \"\"\"\n",
    "    Suppose dataset will generate tuple of structure (feature_vec, target_vec, weight_vec, meta_vec).\n",
    "    Suppose target is in [0, 1, 2], we want to exclude target = 2\n",
    "    \"\"\"\n",
    "    if target == 2:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "ds = ds.unbatch().filter(filter_by_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05960a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(feat, target, weight, meta):\n",
    "    \"\"\"\n",
    "    Suppose meta[0] is sample level random seed, raning from 0~99\n",
    "    \"\"\"\n",
    "    return tf.math.logical_and(\n",
    "        tf.math.greater(tf.math.abs(tf.strings.to_number(meta[0], tf.float32)), 10.0),\n",
    "        tf.math.less(tf.math.abs(tf.strings.to_number(meta[0], tf.float32)), 30.0)\n",
    "    )\n",
    "\n",
    "\n",
    "ds = ds.unbatch().filter(downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude meta column from dataset, or model.fit will fail\n",
    "\n",
    "ds = ds.map(lambda fvec, target, wgt, meta: (fvec, target, wgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache tf dataset once transformation is done\n",
    "tf_cache_dir = ''\n",
    "\n",
    "cached_ds = ds.cache(tf_cache_dir).shffule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989aed9a",
   "metadata": {},
   "source": [
    "# multi thread model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1b1b9",
   "metadata": {},
   "source": [
    "Cause python interpreter has global interpreter lock, only one thread is allowed to run at the same time. Multithread is not accelerating code speed here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22618787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(ds,\n",
    "                   models,\n",
    "                   meta_list,\n",
    "                   target_col_name,\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Run model prediction.\n",
    "    :param ds: tf dataset object, returning tuple of (feature_vec, target, weight, meta_columns).\n",
    "    :param models: list of tuple, where first element is model name, second element is loaded tf model.\n",
    "    :param meta list: dataset meta columns.\n",
    "    :param target_col_name: target column name.\n",
    "    \n",
    "    :return: dataframe of prediction result, score columns are take from first element of model list.\n",
    "    \"\"\"\n",
    "    import multiprocessing\n",
    "    \n",
    "    def _predict(model, feat):\n",
    "        return model.predict(feat)\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    rec_cnt = 0\n",
    "    # thread number may cause process shutdown if predicting very large data\n",
    "    with multiprocessing.pool.ThreadPool(8) as pool:\n",
    "        for r in ds:\n",
    "            rec_cnt += r[0].shape[0]\n",
    "            print(f'record number: {rec_cnt}')\n",
    "            \n",
    "            scores = pool.starmap(_predict, [(model, r[0]) for _, model in models])\n",
    "            \n",
    "            metas = r[-1].numpy()\n",
    "            target_vec = r[1]\n",
    "            data = np.concatenate([metas] + [target_vec] + scores, axis=1)\n",
    "            df = pd.DataFrame(data, columns=meta_list + [target_col_name] + [name for name, _ in models])\n",
    "            final_df = pd.concat([final_df, df])\n",
    "        \n",
    "    for c in meta_list:\n",
    "        final_df[c] = final_df[c].str.decode('UTF-8')\n",
    "        \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf07ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f62a6bd",
   "metadata": {},
   "source": [
    "## single thread prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a4c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(models, ds, meta_list):\n",
    "    \"\"\"\n",
    "    run prediction for models.\n",
    "    : param models: list of tuple, first element is model name, second element is tf model\n",
    "    \"\"\"\n",
    "    final_df = pd.DataFrame()\n",
    "    for r in ds:\n",
    "        scores = []\n",
    "        for _, model in models:\n",
    "            score = model.predict(r[0])\n",
    "            scores.append(score)\n",
    "        metas = r[-1].numpy()\n",
    "        data = np.concatenate([metas] + scores, axis=1)\n",
    "        df = pd.DataFrame(data, columns=meta_list + [f'{name}_score' for name, _ in models])\n",
    "        for c in meta_list:\n",
    "            df[c] = df[c].str.decode('UTF-8')\n",
    "        final_df = pd.concat([final_df, df])\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6181dff",
   "metadata": {},
   "source": [
    "# inspect dataset elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deafd060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = tf.data.TFRecordDataset(filenames=filenames,\n",
    "                                  compression_type='GZIP',\n",
    "                                  num_parallel_reads=tf.data.experimental.AUTOTUNE,\n",
    "                                 )\n",
    "\n",
    "for e in dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(e.numpy())\n",
    "    if len(example.features.feature['new_weight'].bytes_list.value[0]) == 0:\n",
    "        print(example.features.feature['new_weight'])\n",
    "\n",
    "\n",
    "for e in dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(e.numpy())\n",
    "\n",
    "    for k, v in example.features.feature.items():\n",
    "        if v.WhichOneof('kind') != 'float_list':\n",
    "            print(k)\n",
    "\n",
    "\n",
    "for k, feature in example.features.feature.items():\n",
    "    print(f\"feature name {k}, {feature.WhichOneof('kind')}\")\n",
    "    if feature.WhichOneof('kind') == 'float_list':\n",
    "        print(feature.float_list.value)\n",
    "    elif feature.WhichOneof('kind') == 'bytes_list':\n",
    "        print(feature.bytes_list.value)\n",
    "    elif feature.WhichOneof('kind') == 'int64_list':\n",
    "        print(feature.int64_list.value)\n",
    "    else:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a5d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee715032",
   "metadata": {},
   "source": [
    "# tensorflow negative infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93243db",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_inf = tf.constant(-np.inf, shape=[1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32bb0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906d54d5",
   "metadata": {},
   "source": [
    "# TF log callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(model_log_dir, model_name)\n",
    "model_log_callback = tf.keras.callbacks.TensorBoard(log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1da08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec168d5a",
   "metadata": {},
   "source": [
    "# tf model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_filepath = os.path.join(expt_ckdir, \"model-{epoch:02d}.ckpt\")\n",
    "ck_callback = ModelCheckpoint(ck_filepath, \n",
    "                              monitor='loss',\n",
    "                              verbose=1,\n",
    "                              save_best_only=False,\n",
    "                              mode='min',\n",
    "                              save_weights_only=False, \n",
    "                              save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af9d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143f2aac-e588-414f-8e0b-5afca30c5485",
   "metadata": {},
   "source": [
    "# parse string as number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c0f97-8066-40b9-9de9-20954fef3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc21 = tf.cond(\n",
    "    tf.strings.length(tf.strings.strip(meta[ucc21_idx])) == 0,\n",
    "    lambda: -999.0,\n",
    "    lambda: tf.strings.to_number(\n",
    "        tf.strings.substr(tf.strings.strip(meta[ucc21_idx]), 0, 10),\n",
    "        tf.float32,\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec8d5d3-8d91-4476-8c8e-af1d2a15edcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e0fea6-e067-4368-9c2f-6be69eba1bae",
   "metadata": {},
   "source": [
    "# parse tfrecord given meta list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda2782-87d6-4043-8475-5cc4ebdb70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "processed_train_dataset = train_dataset.unbatch()\\\n",
    "                        .filter(filter_fn)\\\n",
    "                        .map(retarget)\\\n",
    "                        .map(reweight)\\\n",
    "                        .batch(batch_size)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for e in processed_train_dataset.take(10):\n",
    "    ret = pd.DataFrame(data=np.concatenate([e[-1].numpy(), e[1].numpy()], axis=1), columns=meta_columns + ['train_tagging'])\n",
    "    df = pd.concat([df, ret])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e2776-20f8-400a-8778-f6d7209ee081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b04ab7-2750-4964-90c1-634291dca531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d99af0cf-6aee-4e0b-8db0-d38c013dc512",
   "metadata": {},
   "source": [
    "# tensorflow prediction and save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe58759-c2a9-4e51-8cbe-b5ecb9505b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_ckpts = [] # tf model checkpoint names\n",
    "tf_models = [] # loaded tf checkpoints\n",
    "cached_oot_dataset = None # tfreocrd dataset, assume return (meta, feature, label) tuple\n",
    "meta_columns = ['target_col_name'] # model training target column name\n",
    "\n",
    "prediction_result_path = '' # path to save prediction result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c499a25-7dfb-4f72-bcdb-f1e67875dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('begin prediction')\n",
    "\n",
    "predict_list = []\n",
    "rec_size = 0\n",
    "\n",
    "\n",
    "# cache oot dataset\n",
    "batch_cnt = 0\n",
    "for e in cached_oot_dataset:\n",
    "    batch_cnt += 1\n",
    "print(f'total batch cnt', batch_cnt)\n",
    "\n",
    "\n",
    "# prediction\n",
    "for feature, target, weight, meta in cached_oot_dataset:\n",
    "    rec_size += meta.shape[0]\n",
    "    print(rec_size, time.ctime())\n",
    "\n",
    "    score_list = []\n",
    "    for model in tf_models:\n",
    "        score = model.predict(feature)\n",
    "        # assume sf bad score is in score[0]\n",
    "        if isinstance(score, list):\n",
    "            score = score[0]\n",
    "        score_list.append(score)\n",
    "    predict_list.append(np.hstack([meta.numpy(), np.hstack(target)] + score_list))\n",
    "\n",
    "\n",
    "# save prediction result\n",
    "print(\"save prediction result to file\")\n",
    "score_name_list = model_ckpts\n",
    "model_predict = pd.DataFrame(np.vstack(predict_list), columns=meta_columns + target_columns + score_name_list)\n",
    "\n",
    "\n",
    "def decode_val(x):\n",
    "    try:\n",
    "        return x.decode()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "for col in model_predict.columns:\n",
    "    model_predict[col] = model_predict[col].apply(decode_val)\n",
    "    \n",
    "\n",
    "tgt_dir = os.path.dirname(prediction_result_path)\n",
    "os.makedirs(tgt_dir, exist_ok=True)\n",
    "model_predict.to_csv(prediction_result_path, index=False, sep='\\x07')\n",
    "print(f\"prediction result saved to {prediction_result_path}\")\n",
    "print('=' * 120)\n",
    "\n",
    "\n",
    "print('prediction columns')\n",
    "print('\\n'.join(model_predict.columns.to_list()))\n",
    "print('=' * 120)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541d9d2-6d93-44dc-b0f4-ed4b92c36af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f87b3-54f3-4f18-8c89-d9e01e147c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701b700-6b39-4a3b-870d-49955d3ed96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
