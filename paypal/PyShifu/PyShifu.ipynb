{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9939d0d6",
   "metadata": {},
   "source": [
    "# expand shifu bining Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c66ee-c1a8-4950-b70a-ee8bd302cb9c",
   "metadata": {},
   "source": [
    "- Shifu WOE calculation: good distribution / bad distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba297a4d-24b1-4dc2-ae47-22501a8d6f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e109e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_bin_info(x):\n",
    "    \"\"\"expand shifu bin info as columns in dataframe.\n",
    "    :param x: row of shifu binning result.\n",
    "    \n",
    "    :return: a pandas series.\n",
    "    \"\"\"\n",
    "\n",
    "    ret = {}\n",
    "    keys = [\n",
    "        'binBoundary',\n",
    "        'binCountPos',\n",
    "        'binPosRate',\n",
    "        'binWeightedPos',\n",
    "        'binWeightedPosRate',\n",
    "        'binCntPosDis',\n",
    "        'binWgtPosDis',\n",
    "        'binCountWoe',\n",
    "        'binWeightedWoe',\n",
    "        'binCountIV',\n",
    "        'binWeightedIV',\n",
    "        'binCountNeg',\n",
    "        'binWeightedNeg',\n",
    "        'binCntNegDis',\n",
    "        'binWgtNegDis',\n",
    "    ]\n",
    "\n",
    "    bin_cnt_pos = x['binCountPos']\n",
    "    bin_wgt_pos = x['binWeightedPos']\n",
    "\n",
    "    bin_cnt_neg = x['binCountNeg']\n",
    "    bin_wgt_neg = x['binWeightedNeg']\n",
    "\n",
    "    bin_cnt_woe = x['binCountWoe']\n",
    "    bin_wgt_woe = x['binWeightedWoe']\n",
    "\n",
    "    # binPosDis\n",
    "    bin_cnt_pos_dis = np.zeros(len(bin_cnt_pos))\n",
    "    bin_wgt_pos_dis = np.zeros(len(bin_wgt_pos))\n",
    "    for i in range(len(bin_cnt_pos)):\n",
    "        bin_cnt_pos_dis[i] = bin_cnt_pos[i] / sum(bin_cnt_pos)\n",
    "        bin_wgt_pos_dis[i] = bin_wgt_pos[i] / sum(bin_wgt_pos)\n",
    "    ret['binCntPosDis'] = bin_cnt_pos_dis\n",
    "    ret['binWgtPosDis'] = bin_wgt_pos_dis\n",
    "\n",
    "    # binNegDis\n",
    "    bin_cnt_neg_dis = np.zeros(len(bin_cnt_neg))\n",
    "    bin_wgt_neg_dis = np.zeros(len(bin_wgt_neg))\n",
    "    for i in range(len(bin_cnt_neg)):\n",
    "        bin_cnt_neg_dis[i] = bin_cnt_neg[i] / sum(bin_cnt_neg)\n",
    "        bin_wgt_neg_dis[i] = bin_wgt_neg[i] / sum(bin_wgt_neg)\n",
    "    ret['binCntNegDis'] = bin_cnt_neg_dis\n",
    "    ret['binWgtNegDis'] = bin_wgt_neg_dis\n",
    "\n",
    "    # binWeightedPosRate\n",
    "    bin_wgt_pos_rate = np.zeros(len(bin_wgt_pos))\n",
    "    for i in range(len(bin_wgt_pos_rate)):\n",
    "        if abs(bin_wgt_pos[i] + bin_wgt_neg[i]) < 1e-8:\n",
    "            bin_wgt_pos_rate[i] = 0\n",
    "        else:\n",
    "            bin_wgt_pos_rate[i] = bin_wgt_pos[i] / (bin_wgt_pos[i] + bin_wgt_neg[i])\n",
    "    ret['binWeightedPosRate'] = bin_wgt_pos_rate.tolist()\n",
    "\n",
    "    # binCountIV\n",
    "    bin_cnt_iv = np.zeros(len(bin_cnt_pos))\n",
    "    for i in range(len(bin_cnt_iv)):\n",
    "        bin_cnt_iv[i] = (bin_cnt_neg_dis[i] - bin_cnt_pos_dis[i]) * bin_cnt_woe[i]\n",
    "    ret['binCountIV'] = bin_cnt_iv.tolist()\n",
    "\n",
    "    # binWeightedIV\n",
    "    bin_wgt_iv = np.zeros(len(bin_wgt_pos))\n",
    "    for i in range(len(bin_wgt_iv)):\n",
    "        bin_wgt_iv[i] = (bin_wgt_neg_dis[i] - bin_wgt_pos_dis[i]) * bin_wgt_woe[i]\n",
    "    ret['binWeightedIV'] = bin_wgt_iv.tolist()\n",
    "\n",
    "    for k in keys:\n",
    "        if k in ret:\n",
    "            continue\n",
    "        ret[k] = x[k]\n",
    "\n",
    "    for k in keys:\n",
    "        if k == 'binBoundary':\n",
    "            continue\n",
    "        ret[k] = np.round(ret[k], 8).tolist()\n",
    "\n",
    "    return pd.Series(data=ret, index=keys)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76daae38-777b-4a07-b5da-c377d79b8731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ab095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyshifu.ShifuEngine import Shifu\n",
    "\n",
    "shifu_local_dir = ''\n",
    "shifu_model_name = ''\n",
    "\n",
    "shifu_model = Shifu.load(os.path.join(shifu_local_dir, shifu_model_name))\n",
    "config = pd.DataFrame(shifu_model.column_config.get_dict())\n",
    "\n",
    "config['missingPercentage'] = config['columnStats'].map(lambda x: x['missingPercentage'])\n",
    "config['mean'] = config['columnStats'].map(lambda x: x['mean'])\n",
    "config['min'] = config['columnStats'].map(lambda x: x['min'])\n",
    "config['max'] = config['columnStats'].map(lambda x: x['max'])\n",
    "config['iv'] = config['columnStats'].map(lambda x: x['iv'])\n",
    "config['totalCount'] = config['columnStats'].map(lambda x: x['totalCount'])\n",
    "config['columnFlag'] = config['columnFlag'].map(lambda x: 'Meta' if x is None else x)\n",
    "config['model_name'] = shifu_model_name\n",
    "\n",
    "r = config['columnBinning'].apply(expand_bin_info)\n",
    "config = config.join(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6a8c7-ab42-435e-9434-c5b94d260ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _seg_num(v):\n",
    "    import re\n",
    "    m = re.search(r'_seg([0-9]+)$', v)\n",
    "    if not m:\n",
    "        return 0\n",
    "    return int(m.group(1))\n",
    "\n",
    "if not 'seg_num' in config.columns:\n",
    "    config.insert(1, 'seg_num', '0')\n",
    "    \n",
    "config['seg_num'] = config['columnName'].map(_seg_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93753cd3-552c-4538-9f96-787afb8ccab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67b0cfbe",
   "metadata": {},
   "source": [
    "# load shifu SE ranking result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05356e-e699-466e-94da-268d8c58b16a",
   "metadata": {},
   "source": [
    "- high rms means high importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_ranking = pd.read_csv(os.path.join(shifu_folder, 'varsel', 'se.0'),\n",
    "                                      sep='\\t', \n",
    "                                      names=['column_index', 'column_name', 'mean', 'rms', 'variance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb72df",
   "metadata": {},
   "source": [
    "# load shifu ModelConfig as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d1f0f-6cc1-4b96-a41b-6e3cd92c1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_config = pd.DataFrame(shifu_model.column_config.get_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de920b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f154232",
   "metadata": {},
   "source": [
    "# shifu test filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model.test('-filter', '-n', '1000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b110469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "169f82f7",
   "metadata": {},
   "source": [
    "# shifu rebin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f12764-6ff0-46e1-9f32-abb3a58102dc",
   "metadata": {},
   "source": [
    "- bic: min instanc in each bucket\n",
    "- n: expected bin num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28997639",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model.stats('-rebin', '-n', '6', '-bic', '2000', '-ivr', '0.98')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cb295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "915acbf4-2094-49e4-a517-3d629d4f54b4",
   "metadata": {},
   "source": [
    "# shifu GBT config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5f17a1-1181-4380-923f-be2c8503b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = shifu_model.model_config\n",
    "\n",
    "# GBT config\n",
    "model_config.train.baggingNum = 1\n",
    "model_config.train.validSetRate = 0.2\n",
    "model_config.train.numTrainEpochs = 500\n",
    "model_config.train.algorithm = 'GBT'\n",
    "model_config.train.params['TreeNum'] = 500\n",
    "model_config.train.params['FeatureSubsetStrategy'] = 'ALL'\n",
    "model_config.train.params['MaxDepth'] = 5\n",
    "model_config.train.params['Impurity'] = 'variance'\n",
    "model_config.train.params['LearningRate'] = 0.05\n",
    "model_config.train.params['MinInstancesPerNode'] = 200\n",
    "model_config.train.params['Loss'] = 'squared'\n",
    "model_config.train.params['MinInfoGain'] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e000c-c677-4b8a-8899-198da5ad324a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf620d9d",
   "metadata": {},
   "source": [
    "# shifu CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "Usage: shifu COMMAND\n",
    "where COMMAND is one of:\n",
    "    new <ModelSetName> [-t <NN|LR|SVM|DT>]  Create a new model set.\n",
    "    init                                    Create initial ColumnConfig.json and upload to HDFS.\n",
    "    stats                                   Calculate statistics on HDFS and update local ColumnConfig.json.\n",
    "    stats –c                                Calculate feature correltion.\n",
    "    varselect/varsel [-reset]               Variable selection, will update finalSelect in ColumnConfig.json.\n",
    "    normalize/norm                          Normalize the columns with finalSelect as true.\n",
    "    train [-dry]                            Train the model with the normalized data.\n",
    "    posttrain                               Post-process data after training models.\n",
    "    eval                                    Run all eval sets.\n",
    "    eval -list                              Lis all eval set.\n",
    "    eval -new     <EvalSetName>             Create a new eval set.\n",
    "    eval -delete  <EvalSetName>             Delete an eval set.\n",
    "    eval -run     <EvalSetName>             Run eval set evaluation.\n",
    "    eval -score   <EvalSetName>             Scoring evaluation dataset.\n",
    "    eval -norm    <EvalSetName>             Normalize evaluation dataset.\n",
    "    eval -confmat <EvalSetName>             Compute the TP/FP/TN/FN based on scoring\n",
    "    eval -perf    <EvalSetName>             Calculate the model performance based on confmat\n",
    "    export [-t pmml|columnstats] [-c]       Export model to PMML format or export ColumnConfig.\n",
    "    version|v|-v|-version                   Print version of current package.\n",
    "    help|h|-h|-help                         Help message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa838702-1e45-4c0b-8cb2-05cc3eb92954",
   "metadata": {},
   "source": [
    "## useful shifu config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4c63f-fc08-4f67-aa22-14800f5fe8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a84675-af7d-4c03-a12e-fbf4017f2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default shifu config\n",
    "import os\n",
    "from pyshifu.ShifuConf import shifuConf\n",
    "\n",
    "# increase java memory config in local, may fail when loading calculcated correlation matrix if memory is too small.\n",
    "os.environ['SHIFU_OPTS'] = '-Xms4G -Xmx16G'\n",
    "\n",
    "# increase hadoop map / reducer memory setting, may fail at hadoop jobs if too small\n",
    "shifuConf.set('mapreduce.map.java.opts', '-Xms8000m -Xmx16000m -server -XX:MaxPermSize=64m -XX:PermSize=64m -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:ParallelGCThreads=8 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps')\n",
    "shifuConf.set('mapreduce.reduce.java.opts', '-Xms8000m -Xmx16000m -server -XX:MaxPermSize=64m -XX:PermSize=64m')\n",
    "shifuConf.set('shifu.norm.shuffle.size', '200')\n",
    "shifuConf.set('mapreduce.map.memory.mb','16000')\n",
    "shifuConf.set('mapreduce.reduce.memory.mb','16000')\n",
    "shifuConf.set('hadoopJobQueue', queue)\n",
    "# to avoid norm parquet failure\n",
    "shifuConf.set('parquet.enable.summary-metadata', 'false') \n",
    "shifuConf.save()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a1e2f-dbe0-47fa-b992-c476de7af244",
   "metadata": {},
   "source": [
    "# load shifu column config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4be4b-f660-454a-9a3c-f64779733bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('path_to_column_config.json') as f:\n",
    "    df = pd.DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc591b-4f1e-461b-a0a6-5c8aca8af78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4984943-d360-4f85-849c-7bb81f922425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOE_ZSCORE = (WOE of Xi -  WOE_MEAN)/WOE_STD\n",
    "\n",
    "# WOE_MEAN =  WOE * WOE_COUNT\n",
    "# WOE_STD = sqrt(  ( SUM(WOE*WOE*COUNT )  - COUNT* (WOE_MEAN*WOE_MEAN)) / (COUNT-1) )\n",
    "\n",
    "pos = v['columnBinning']['binCountPos']\n",
    "neg = v['columnBinning']['binCountNeg']\n",
    "woe = v['columnBinning']['binCountWoe']\n",
    "\n",
    "count = 0\n",
    "woeSum = 0\n",
    "squaredSum = 0\n",
    "\n",
    "for k, v in enumerate(pos):\n",
    "    count += (pos[k] + neg[k])\n",
    "    woeSum += (pos[k] + neg[k]) * woe[k]\n",
    "    squaredSum += woe[k] * woe[k] * (pos[k] + neg[k])\n",
    "\n",
    "print(woeSum / count)\n",
    "print(np.sqrt((squaredSum - count * (woeSum / count) * (woeSum / count)) / (count - 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30d98a-c231-4e0a-82b3-fde2a890ae67",
   "metadata": {},
   "source": [
    "# shifu filter expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75a042-5150-442b-81eb-e5106441fc3f",
   "metadata": {},
   "source": [
    "notes:\n",
    "- can not use number value in list, `col in [1, 2]` will yeild empty set, no matter data type of col\n",
    "- can not use integer value if col value is float, `col >= 1` evaludated as false if col is float type value, use `col >= 1.0` in stead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81421b-9e50-4af8-a82a-6a82963815da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eq\n",
    "expr = \"col = 1\"\n",
    "\n",
    "# in list\n",
    "expr = \"col =~ ['O', 'P', 'Y']\"\n",
    "\n",
    "# empty col\n",
    "expr = \"empty(col)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d3465-b2b2-461b-9736-a32459c897b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e21ace05-e8a2-4097-91a5-d8c0adb957d0",
   "metadata": {},
   "source": [
    "# load and parse correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44a4b7-215c-40f2-b8c1-d932140dbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df = None # should contain variable IV\n",
    "\n",
    "corr_df = pd.read_csv(corr_file_path, skiprows=1,)\n",
    "corr_df = corr_df.drop(columns=['Unnamed: 0']).rename(columns={'ColumnName': 'variable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc8d10-e079-47ca-87ba-b0984b4560b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_thres = 0.9\n",
    "corr_rm = []\n",
    "\n",
    "variables = corr_df['variable'].to_list()\n",
    "\n",
    "for i, a in enumerate(variables):\n",
    "    for b in variables[i+1:]:\n",
    "        corr = corr_df[\n",
    "            corr_df['variable'] == a\n",
    "        ][b].iloc[0]\n",
    "        \n",
    "        corr = float(corr)\n",
    "        if abs(corr) >= corr_thres:\n",
    "            a_iv = iv_df[iv_df['variable'] == a]['iv'].iloc[0]\n",
    "            b_iv = iv_df[iv_df['variable'] == b]['iv'].iloc[0]\n",
    "            to_rm = a if a_iv < b_iv else b\n",
    "            print(f'{a} iv: {a_iv}, {b} iv: {b_iv}, correlation: {corr}, rm: {to_rm}')\n",
    "            corr_rm.append(to_rm)\n",
    "\n",
    "print(f'correlation removed variable num: {len(corr_rm)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef26a6-4525-4a4f-ae45-a777b59ba511",
   "metadata": {},
   "source": [
    "# reduce file normed file size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93defcf3-43c8-4d0d-a392-b6fe59da9b0e",
   "metadata": {},
   "source": [
    "shifu.norm.shuffle.size: total file num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80114a1d-9547-459d-b0b8-50e4625583e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model.norm('-shuffle', '-Dshifu.norm.shuffle.size=100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dba8fa-e2ea-474a-85e0-a51b2f28d346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37241353-d7a9-4b2c-97e9-ddcc23729a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdb6b2a8-f354-4d6e-9232-b9d8c163be0c",
   "metadata": {},
   "source": [
    "# shifu correlation memory config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b909d6-58aa-45c0-8e98-6ad2801f576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config pyshifu java opts\n",
    "shifu.stats('-c', '-Dshifu.stats.corr.reuse=true') # reuse previous calculated stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59947a-1e5c-419c-9ef4-4ce0fc3feeeb",
   "metadata": {},
   "source": [
    "## shifu norm as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8725b-e04b-4bc1-9d2c-a192c092f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 'xxx' # eval set name in your shifu config\n",
    "\n",
    "shifu_model.eval('-norm', data_set, '-Dshifu.output.data.format=parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fe248-30e3-40fd-b839-9b3bed92d5a5",
   "metadata": {},
   "source": [
    "# load shifu PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2ad9d-a61d-48ee-b709-72f46236f0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058102a8-adfe-4692-9f3e-c9ad50047945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8006a97-58b9-43ed-b4cd-c9c3814027eb",
   "metadata": {},
   "source": [
    "# parse Shifu SE error from log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db4583-af3b-4e1d-8f91-f17c43266742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_SE_error(log_path):\n",
    "    with open(log_path) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    train_err = []\n",
    "    validation_err = []\n",
    "    for line in lines:\n",
    "        m = re.search(r'Training Error:([0-9]+\\.[0-9]+)', line)\n",
    "        if m:\n",
    "            train_err.append(float(m.group(1)))\n",
    "        m = re.search(r'Validation Error:([0-9]+\\.[0-9]+)', line)\n",
    "        if m:\n",
    "            validation_err.append(float(m.group(1)))\n",
    "            \n",
    "    return pd.DataFrame(data={'traininng error': train_err, 'validation error': validation_err})\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
