{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ff0da3-f1f3-455d-9eeb-427947fa4b45",
   "metadata": {},
   "source": [
    "# training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91812c-37f2-46f3-97b8-e98fd10da620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from model_automation.utils.rmr import run_cmd\n",
    "from pyshifu.ShifuConf import shifuConf\n",
    "from pyshifu.ShifuEngine import Shifu\n",
    "\n",
    "\n",
    "dev_data_dir = ''\n",
    "oot_data_dir = ''\n",
    "\n",
    "shifu_model_name = 'shifu_training'\n",
    "shifu_local_dir = 'shifu_model'\n",
    "shifu_hdfs_dir = ''\n",
    "shifu_job_queue = 'risk_gds_focus'\n",
    "\n",
    "weight_column = 'raw_dol_amt'\n",
    "target_column = 'is_unauth_bad'\n",
    "\n",
    "dev_filter_expr = \"1 == 1\"\n",
    "oot_filter_expr = \"1 == 1\"\n",
    "\n",
    "pos_tag = '1'\n",
    "neg_tag = '0'\n",
    "\n",
    "data_delimiter = '\\x07'\n",
    "\n",
    "dev_meta_columns_path = 'driver_meta_columns.txt'\n",
    "oot_meta_columns_path = 'driver_meta_columns.txt'\n",
    "\n",
    "candidate_vars_path = 'candidate_vars.txt'\n",
    "categorical_vars_path = 'categorical_vars.txt'\n",
    "force_rm_vars_path = 'force_rm_vars.txt'\n",
    "\n",
    "seg_expr = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d091ebe-60bc-4319-bfc7-196e75f65c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_meta_columns = pd.read_csv(dev_meta_columns_path, names=['col'])['col'].to_list()\n",
    "oot_meta_columns = pd.read_csv(oot_meta_columns_path, names=['col'])['col'].to_list()\n",
    "\n",
    "candidate_vars = pd.read_csv(candidate_vars_path, names=['col'])['col'].to_list()\n",
    "categorical_vars = pd.read_csv(categorical_vars_path, names=['col'])['col'].to_list()\n",
    "force_remove_vars = pd.read_csv(force_rm_vars_path, names=['col'])['col'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2f14f-f4a7-4b14-b1df-3cb0ab23cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_or_load_shifu_instance(shifu_model_name, shifu_local_dir, shifu_hdfs_dir, reuse=True):\n",
    "    if reuse:\n",
    "        print(f'reusing shifu model {shifu_model_name}')\n",
    "        shifu_model = Shifu.load(folder=shifu_local_dir, name=shifu_model_name)\n",
    "        return shifu_model\n",
    "    \n",
    "    print('initializing new shifu model')\n",
    "    local_dir = os.path.join(shifu_local_dir, shifu_model_name)\n",
    "    if os.path.exists(local_dir):\n",
    "        shutil.rmtree(local_dir)\n",
    "    os.makedirs(os.path.dirname(local_dir), exist_ok=True)\n",
    "    \n",
    "    run_cmd(f\"hadoop fs -rm -r -f -skipTrash {os.path.join(shifu_hdfs_dir, shifu_model_name)}\")\n",
    "    shifu_model = Shifu.new(folder=shifu_local_dir, name=shifu_model_name)\n",
    "    return shifu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427edfa9-5791-4849-b18c-ea599d3b74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_shifu(shifu_model,\n",
    "                 shifu_local_dir,\n",
    "                 shifu_hdfs_dir,\n",
    "                 shifu_job_queue,\n",
    "                 data_delimiter,\n",
    "                 dev_data_dir,\n",
    "                 oot_data_dir,\n",
    "                 weight_column,\n",
    "                 target_column,\n",
    "                 pos_tag,\n",
    "                 neg_tag,\n",
    "                 dev_filter_expr,\n",
    "                 oot_filter_expr,\n",
    "                 candidate_vars,\n",
    "                 categorical_vars,\n",
    "                 force_remove_vars,\n",
    "                 dev_meta_columns,\n",
    "                 oot_meta_columns,\n",
    "                 seg_expr=None\n",
    "                ):\n",
    "    model_config = shifu_model.model_config\n",
    "    local_shifu_model_dir = os.path.join(shifu_local_dir, shifu_model.name)\n",
    "\n",
    "    # basic\n",
    "    model_config.basic.customPaths = {'hdfsModelSetPath': shifu_hdfs_dir}\n",
    "\n",
    "    # dataset\n",
    "    model_config.dataSet.dataPath = dev_data_dir\n",
    "    model_config.dataSet.dataDelimiter = data_delimiter\n",
    "    model_config.dataSet.headerPath = os.path.join(dev_data_dir, '.pig_header')\n",
    "    model_config.dataSet.headerDelimiter = data_delimiter\n",
    "    model_config.dataSet.weightColumnName = weight_column\n",
    "    model_config.dataSet.targetColumnName = target_column\n",
    "    model_config.dataSet.metaColumnNameFile = 'columns/meta.column.names'\n",
    "    model_config.dataSet.posTags = [pos_tag]\n",
    "    model_config.dataSet.negTags = [neg_tag]\n",
    "    model_config.dataSet.categoricalColumnNameFile = 'columns/categorical.column.names'\n",
    "    model_config.dataSet.missingOrInvalidValues = ['', '*', '#', '?', 'null', '~', '.', 'NULL', 'NONE', 'None', 'none', '-999', 'NaN']\n",
    "    model_config.dataSet.filterExpressions = dev_filter_expr\n",
    "    \n",
    "    if seg_expr is not None:\n",
    "        model_config.dataSet.segExpressionFile = \"columns/segments.file\"\n",
    "        # write segment expression\n",
    "        seg_expr_file_path = os.path.join(local_shifu_model_dir, model_config.dataSet.segExpressionFile)\n",
    "        os.makedirs(os.path.dirname(seg_expr_file_path), exist_ok=True)\n",
    "        with open(seg_expr_file_path, 'w') as f:\n",
    "            f.write(seg_expr)\n",
    "            print(f'segment file written to {seg_expr_file_path}')\n",
    "    \n",
    "    with open(os.path.join(local_shifu_model_dir, model_config.dataSet.categoricalColumnNameFile), 'w') as f:\n",
    "        f.write('\\n'.join(categorical_vars))\n",
    "\n",
    "    with open(os.path.join(local_shifu_model_dir, model_config.dataSet.metaColumnNameFile), 'w') as f:\n",
    "        f.write('\\n'.join(dev_meta_columns))\n",
    "    \n",
    "    # stats\n",
    "    model_config.stats.maxNumBin = 10\n",
    "    model_config.stats.cateMaxNumBin = 10\n",
    "    model_config.stats.binningMethod = 'EqualTotal'\n",
    "    model_config.stats.binningAlgorithm = 'SPDTI'\n",
    "    \n",
    "    # norm\n",
    "    model_config.normalize.normType = \"WOE_ZSCORE\"\n",
    "    model_config.normalize.stdDevCutOff = 6.0\n",
    "    model_config.normalize.sampleNegOnly = False\n",
    "\n",
    "    # varsel\n",
    "    model_config.varSelect.forceEnable = True\n",
    "    model_config.varSelect.candidateColumnNameFile = 'columns/candidate.column.names'\n",
    "    model_config.varSelect.filterEnable = True\n",
    "    model_config.varSelect.filterBy = 'IV'\n",
    "    model_config.varSelect.filterNum = 1000\n",
    "    model_config.varSelect.minIvThreshold = 0.001\n",
    "    \n",
    "    with open(os.path.join(local_shifu_model_dir, model_config.varSelect.forceRemoveColumnNameFile), 'w') as f:\n",
    "        f.write('\\n'.join(force_remove_vars))\n",
    "        \n",
    "    with open(os.path.join(local_shifu_model_dir, model_config.varSelect.candidateColumnNameFile), 'w') as f:\n",
    "        f.write('\\n'.join(candidate_vars))\n",
    "    \n",
    "    # GBT config\n",
    "    model_config.train.baggingNum = 1\n",
    "    model_config.train.validSetRate = 0.2\n",
    "    model_config.train.numTrainEpochs = 10\n",
    "    model_config.train.algorithm = 'GBT'\n",
    "    model_config.train.params['TreeNum'] = 10\n",
    "    model_config.train.params['FeatureSubsetStrategy'] = 'ALL'\n",
    "    model_config.train.params['MaxDepth'] = 3\n",
    "    model_config.train.params['Impurity'] = 'variance'\n",
    "    model_config.train.params['LearningRate'] = 0.05\n",
    "    model_config.train.params['MinInstancesPerNode'] = 200\n",
    "    model_config.train.params['Loss'] = 'squared'\n",
    "    model_config.train.params['MinInfoGain'] = 0.0\n",
    "\n",
    "    # NN config\n",
    "    # model_config.train.baggingNum = 4\n",
    "    # model_config.train.baggingWithReplacement = False\n",
    "    # model_config.train.baggingSampleRate = 0.9\n",
    "    # model_config.train.sampleNegOnly = False\n",
    "    # model_config.train.numTrainEpochs = 200\n",
    "    # model_config.train.workerThreadCount = 4\n",
    "    # model_config.train.algorithm = \"NN\"\n",
    "    # model_config.train.params['Propagation'] = \"R\"\n",
    "    # model_config.train.params['LearningRate'] = 0.05\n",
    "    # model_config.train.params['DropoutRate'] = 0.1\n",
    "    # model_config.train.params['NumHiddenNodes'] = [128, 64]\n",
    "    # model_config.train.params['NumHiddenLayers'] = 2\n",
    "    # model_config.train.params['L1orL2'] = 'L2'\n",
    "    \n",
    "    # eval\n",
    "    assert len(model_config.evals) == 1\n",
    "    eval2 = copy.deepcopy(model_config.evals[0])\n",
    "    eval2.name = 'eval2'\n",
    "    eval2.dataSet.dataPath = oot_data_dir\n",
    "    eval2.dataSet.dataDelimiter = data_delimiter\n",
    "    eval2.dataSet.headerPath = os.path.join(oot_data_dir, '.pig_header')\n",
    "    eval2.dataSet.headerDelimiter = data_delimiter\n",
    "    eval2.dataSet.filterExpressions = oot_filter_expr\n",
    "    eval2.dataSet.weightColumnName = weight_column\n",
    "    eval2.dataSet.posTags = [pos_tag]\n",
    "    eval2.dataSet.negTags = [neg_tag]\n",
    "    eval2.dataSet.targetColumnName = target_column\n",
    "    eval2.dataSet.metaColumnNameFile = 'columns/eval.meta.column.names'\n",
    "    eval2.scoreMetaColumnNameFile = 'columns/eval.meta.column.names'\n",
    "    eval2.normAllColumns = False\n",
    "\n",
    "    model_config.evals.append(eval2)\n",
    "    \n",
    "    shifu_model.save()\n",
    "        \n",
    "    with open(os.path.join(local_shifu_model_dir, eval2.dataSet.metaColumnNameFile), 'w') as f:\n",
    "        f.write('\\n'.join(dev_meta_columns))\n",
    "    \n",
    "    with open(os.path.join(local_shifu_model_dir, eval2.scoreMetaColumnNameFile), 'w') as f:\n",
    "        f.write('\\n'.join(dev_meta_columns))\n",
    "        \n",
    "    shifu_model.model_config.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473e424-be9b-4154-b6ac-7cd18f83b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SHIFU_OPTS'] = '-Xms4G -Xmx16G'\n",
    "\n",
    "shifuConf.set('hadoopJobQueue', shifu_job_queue)\n",
    "shifuConf.set('mapreduce.map.memory.mb','16000')\n",
    "shifuConf.set('mapreduce.reduce.memory.mb','16000')\n",
    "shifuConf.set('mapreduce.map.java.opts', \"-Xms4G -Xmx16G -server -XX:MaxPermSize=64m -XX:PermSize=64m -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:ParallelGCThreads=8 -verbose:gc -XX:+PrintGC\")\n",
    "shifuConf.set('mapreduce.reduce.java.opts', \"-Xms4G -Xmx16G -server -XX:MaxPermSize=64m -XX:PermSize=64m\")\n",
    "shifuConf.set('parquet.enable.summary-metadata', 'false')\n",
    "\n",
    "shifuConf.save()\n",
    "shifuConf.print_envs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791d8fd-0c56-4653-bcd8-a53fcfc357ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model = init_or_load_shifu_instance(shifu_model_name, shifu_local_dir, shifu_hdfs_dir, reuse=False)\n",
    "\n",
    "config_shifu(shifu_model,\n",
    "             shifu_job_queue=shifu_job_queue,\n",
    "             shifu_local_dir=shifu_local_dir,\n",
    "             shifu_hdfs_dir=shifu_hdfs_dir,\n",
    "             data_delimiter=data_delimiter,\n",
    "             dev_data_dir=dev_data_dir,\n",
    "             oot_data_dir=oot_data_dir,\n",
    "             weight_column=weight_column,\n",
    "             target_column=target_column,\n",
    "             pos_tag=pos_tag,\n",
    "             neg_tag=neg_tag,\n",
    "             dev_filter_expr=dev_filter_expr,\n",
    "             oot_filter_expr=oot_filter_expr,\n",
    "             candidate_vars=candidate_vars,\n",
    "             categorical_vars=categorical_vars,\n",
    "             force_remove_vars=force_remove_vars,\n",
    "             dev_meta_columns=dev_meta_columns,\n",
    "             oot_meta_columns=oot_meta_columns,\n",
    "             seg_expr=seg_expr,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247eda21-d3fa-4881-986b-74de69fcde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change config\n",
    "\n",
    "shifu_model.model_config.train.baggingNum = 1\n",
    "shifu_model.model_config.train.validSetRate = 0.2\n",
    "shifu_model.model_config.train.numTrainEpochs = 10\n",
    "shifu_model.model_config.train.algorithm = 'GBT'\n",
    "shifu_model.model_config.train.params['TreeNum'] = 10\n",
    "shifu_model.model_config.train.params['FeatureSubsetStrategy'] = 'ALL'\n",
    "shifu_model.model_config.train.params['MaxDepth'] = 3\n",
    "shifu_model.model_config.train.params['Impurity'] = 'variance'\n",
    "shifu_model.model_config.train.params['LearningRate'] = 0.05\n",
    "shifu_model.model_config.train.params['MinInstancesPerNode'] = 200\n",
    "shifu_model.model_config.train.params['Loss'] = 'squared'\n",
    "shifu_model.model_config.train.params['MinInfoGain'] = 0.0\n",
    "\n",
    "shifu_model.save()\n",
    "        \n",
    "shifu_model.model_config.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a3f29-b347-4c85-bb30-4388c50f8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model.init()\n",
    "print('finish init')\n",
    "\n",
    "shifu_model.stats()\n",
    "print('finish stats')\n",
    "\n",
    "shifu_model.export('-t', 'columnstats')\n",
    "print('finish exporting columnstats')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39beb067-d24c-4df2-884c-2982dabffe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model.norm()\n",
    "print('finish norm')\n",
    "\n",
    "shifu_model.varsel()\n",
    "print('finish varsel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4aa649-11fe-43bb-a559-e71bd592792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model.train()\n",
    "print('finish train')\n",
    "\n",
    "shifu_model.eval('-score', 'eval2')\n",
    "print('finish eval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363bf98-fc36-4b3c-8fb1-ad643c1a04e2",
   "metadata": {},
   "source": [
    "## way to run shifu FI\n",
    "- set filterBy = 'FI' in shifu varsel config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ff8d7-d77a-44df-9868-693a846650fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run shifu FI\n",
    "shifu_model.varsel('-reset')\n",
    "for i in range(5):   \n",
    "    shifu_model.varsel()\n",
    "    print(f'finish FI iteration {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f5f46-c244-4529-a79e-cd131e1d4dd7",
   "metadata": {},
   "source": [
    "## way to run shifu correlation\n",
    "- when exporting correlation file, you may exncounter OOM error (java exit code: 137), you can either: 1) increase map reduce memory, 2) increase notebook memeory.\n",
    "- need to run stats first\n",
    "- correlation file is saved to shifu_folder/shifu_model_name/correlation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7302dc-0654-452a-ac33-c308ec62ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifu_model.init()\n",
    "print('finish init')\n",
    "\n",
    "shifu_model.stats()\n",
    "print('finish stats')\n",
    "\n",
    "shifu_model.export('-t', 'columnstats')\n",
    "print('finish exporting columnstats')\n",
    "\n",
    "shifu_model.stats('-c', '-Dshifu.stats.corr.reuse=true')\n",
    "print('finish shifu correlation stats')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff7eaa-6db2-4602-971b-b21c5ab4b4f8",
   "metadata": {},
   "source": [
    "## way to run shifu SE\n",
    "- set filterBy = 'SE' in shifu varsel config\n",
    "- SE file is saved to shifu_folder/shifu_model_name/varsel/se.0\n",
    "- need to mannually save se file, or it will be overridded\n",
    "- run `varsel -reset` before each round of `varsel` may run into race condition, when shifu has not generated `se.0` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e54d42-8213-4a7b-b83a-debfa27ade90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filterBy = 'SE' in shifu varsel config\n",
    "\n",
    "shifu_model.init()\n",
    "print('finish init')\n",
    "\n",
    "shifu_model.stats()\n",
    "print('finish stats')\n",
    "\n",
    "shifu_model.export('-t', 'columnstats')\n",
    "print('finish exporting columnstats')\n",
    "\n",
    "shifu_model.norm()\n",
    "print('finish norm')\n",
    "\n",
    "shifu_model.varsel('-reset')\n",
    "\n",
    "for i in range(3):\n",
    "    shifu_model.varsel()\n",
    "    print(f'finish running SE iteration {i}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb2f73-86bb-49f0-afd9-5cc9826f43cb",
   "metadata": {},
   "source": [
    "# way to run shifu PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378ec00-ad22-4b3d-ba0b-aadad2ebb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change config\n",
    "month_col = 'driver_monthly'\n",
    "shifu_model.model_config.stats.psiColumnName = month_col\n",
    "shifu_model.save()\n",
    "shifu_model.model_config.show()\n",
    "\n",
    "# need to run stats first\n",
    "shifu_model.stats()\n",
    "print('finish stats')\n",
    "\n",
    "shifu_model.stats('-psi')\n",
    "print('finish PSI stats')\n",
    "\n",
    "shifu_model.export('-t', 'columnstats')\n",
    "print('finish exporting columnstats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c1bd2-d8ec-4930-baeb-eb83831c2493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ffb95d-4976-46f3-90bf-ee050795b964",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f58fb-6b02-4e42-8dab-5cba3be1ecdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f08d1b-dc4d-4949-b366-0ba929dd3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# download to local\n",
    "\n",
    "from automation_utils.common.hdfs import get_hdfs_to_local_csv\n",
    "lib_path = \"/projects/gds-focus/data/wzhao5/Python3\"\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.append(lib_path)\n",
    "    \n",
    "from fast_perf_v5 import fast_perf_v5\n",
    "\n",
    "\n",
    "eval_score_data_dir = os.path.join(shifu_hdfs_dir, shifu_model_name, 'evals/eval2/EvalScore')\n",
    "local_data_path = f'data/shifu_eval/{shifu_model_name}/eval2_eval_score_tmp.csv'\n",
    "print(f'downloading data from {eval_score_data_dir}')\n",
    "\n",
    "local_data_dir = os.path.dirname(local_data_path)\n",
    "os.makedirs(local_data_dir, exist_ok=True)\n",
    "\n",
    "get_hdfs_to_local_csv(eval_score_data_dir,\n",
    "                      local_data_path,\n",
    "                      os.path.join(eval_score_data_dir, '.pig_header'))\n",
    "print(f'data download to {local_data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f6f74-469a-47dd-86bd-5922f247296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_score_names = ['model0']\n",
    "eval_set = 'eval2'\n",
    "expt_name = 'model_101'\n",
    "eval_data_path = local_data_path\n",
    "eval_result_dir = os.path.dirname(eval_data_path)\n",
    "\n",
    "print('model score names', model_score_names)\n",
    "print('eval data path', eval_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa91af-1772-4188-b4f9-5046f83f6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "excl_eval_result_path = os.path.join(eval_result_dir, f\"gainchart_{expt_name}_{eval_set}.xlsx\")\n",
    "print(f\"gainchart result path: {excl_eval_result_path}\")\n",
    "\n",
    "dim_list = [\n",
    "    'driver_is_oot',\n",
    "    'driver_is_cbp',\n",
    "    'driver_is_fp',\n",
    "    'driver_product',\n",
    "    'driver_is_oot*driver_is_cbp',\n",
    "    'driver_is_oot*driver_is_fp',\n",
    "    'driver_is_oot*driver_product',\n",
    "]\n",
    "\n",
    "args = {\n",
    "    'dataPath': eval_data_path,\n",
    "    'delimiter': '\\x07',\n",
    "    'badList': ['driver_is_cc_bad_v1'],\n",
    "    'scoreList': model_score_names,\n",
    "    'dimList': dim_list,\n",
    "    'xWeight': ['driver_dol_usd_amt', 'driver_dol_usd_amt_cap1k', 'driver_unit_wgt'],\n",
    "    'yWeight': ['driver_dol_usd_amt', 'driver_dol_usd_amt_cap1k', 'driver_unit_wgt'],\n",
    "    'weightAlias': ['dol','dol_cap1k', 'unit'],\n",
    "    'filterExpr': {\n",
    "        '$AND': {\n",
    "            'driver_txn_status': 'Approved',\n",
    "        },\n",
    "    },\n",
    "    'OP': 100,\n",
    "    'TopOP': 100,\n",
    "    'outputFile': excl_eval_result_path\n",
    "}\n",
    "\n",
    "print(f'start running gainchart')\n",
    "perf = fast_perf_v5(**args)\n",
    "perf.run()\n",
    "\n",
    "print(f'finish running model performance evaluation: {expt_name} on {eval_set}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4c175-f01b-4101-9008-1303e2b1c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = perf.output.copy()\n",
    "csv_eval_result_csv_path = os.path.join(eval_result_dir, f\"gainchart_{expt_name}_{eval_set}.csv\")\n",
    "df_out.to_csv(csv_eval_result_csv_path, index=False)\n",
    "print(f'eval result save to {csv_eval_result_csv_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb5304-72bf-45a5-8f0c-d063e6000bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.read_csv(csv_eval_result_csv_path, sep='\\x07')\n",
    "\n",
    "print('overall performance')\n",
    "op_num = 5\n",
    "\n",
    "ret = pd.pivot_table(perf_df[\n",
    "    (perf_df['Metric'] == 'dol Catch_Rate')\n",
    "    & (perf_df['dim_name'].isn([1, '1']))\n",
    "    & (perf_df['dim_value'].isn([1, '1']))\n",
    "],\n",
    "                     index=['score'],\n",
    "                     values=[f'OP{i+1}' for i in range(op_num)])\n",
    "\n",
    "ret = ret[[f\"OP{i+1}\" for i in range(op_num)]]\n",
    "\n",
    "print(ret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
